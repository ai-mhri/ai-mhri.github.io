---
redirect_from: "https://aim-hri.github.io"
---
# Welcome to AI-MHRI 
### The AI for Multimodal Human Robot Interaction Workshop at the Federated AI Meeting (FAIM) 2018 in Stockholm, July 14 and 15

<!---
The intersection of Artificial Intelligence (AI) and Human-Robot Interaction (HRI) has recently emerged as an intriguing technical and intellectual opportunity (e.g., in recent consecutive [AAAI Fall Symposia on AI-HRI in 2014, -15, -16, and -17](https://ai-hri.gihub.io)). Multimodal interaction with robots (M-HRI), including social signals (e.g., the Interspeech satellite workshop 'Vocal Interactivity in-and-between Humans, Animals and Robots' - [VIHAR-2017](http://vihar-2017.vihar.org)), can be also seen as an area within HRI that connects directly to various topics in AI. A full exploration of this intersection, however, has yet to be realized.  The aim of this 1.5 day workshop is to integrate fundamental insights that the AI community and the HRI community have to offer each other within this context.
We intend to frame the discussion by way of the complementary statements _HRI is an AI problem_ and _AI is an HRI problem_ and apply this mutual dependence to a range of relevant topics, including XAI, Planning, NLP, Machine Learning, Image Analysis, Knowledge Representation, Reasoning, (Multimodal) Dialogue, Gesture and Speech Recognition, and Autonomous Systems. In particular, the workshop will emphasize the specific AI and HRI challenges that arise from interacting with embodied agents like robots, as well as the interpretation and generation of social signals emerging from this interaction. Social signals can here refer to communicative modalities of robots and humans in direct interaction (as speech, gaze, or gesture), but it is also possible to view this term more broadly, including more general aspects of societal acceptance of technology, explainability and higher-level signals.
Our aim is to organise an actual _work_-shop rather than a mini-conference, with a focus on discussions around specific topics and areas, based on research area summaries and position papers. 
-->

## -----------------
## Registration information:
To register to the workshop, please use the general registration forms for FAIM workshops, accessible for instance through the registration forms for IJCAI/ECAI at [https://www.ijcai-18.org/register/](https://www.ijcai-18.org/register/). 
## -----------------

The Artificial Intelligence for Multimodal Human Robot Interaction (AI-MHRI) workshop offers a platform for researchers at the intersection of AI and Multimodal HRI.  HRI research studies the interaction between humans and increasingly intelligent and autonomous machines, from the sensory to the physical modality, from problems of learning, social signals, collaboration, to design. Sophisticated AI models and implementations are critical in this endeavor but are not often explicitly addressed.  AI models and implementations, on their part, are often developed without sufficiently considering how humans interact with them, whether they understand them, trust them, and are willing to collaborate with them.  We thus believe that AI is a significant challenge in HRI research and HRI is a significant challenge in AI research, and this mutual significance motivates our workshop. 

Because the AI-MHRI workshop takes place  during the IJCAI/ECAI, AAMAS, and ICML meetings, researchers working on AI, Autonomous Systems, and Machine Learning have an opportunity to contribute to the emerging connection between AI and HRI. This workshop builds on previous AAAI Fall Symposia (AI-HRI 2014, 2015, 2016, and 2017, see [http://ai-hri.github.io](http://ai-hri.github.io)) and connects on previous workshops in the area of social signals in HRI (e.g., Vocal Interactivity in-and-between Humans, Animals and Robots; see [http://vihar-2017.vihar.org](http://vihar-2017.vihar.org)). The AI-MHRI workshop, however, puts a greater emphasis on discussions, joint research development, and identifying promising future directions of the intersection of these fields, rather than strictly adhering to the standard “mini-conference” format. 

## Workshop format:
The two-day workshop will feature three to four invited talks that introduce major perspectives and components of the AI-MHRI interface.  In addition, a significant part of the program on Day 1 will consist of themed sessions in which researchers present short position papers that feature particular perspectives, controversial findings and ideas, novel hypotheses, or future directions — all to provoke discussion and make progress in the exchange between AI and HRI.  We particularly encourage pairs or groups of researchers to jointly write and present position papers that contrast or integrate different viewpoints.  Day 1 will close with a poster session to give junior researchers a chance to present their innovative work.  Day 2 will be reserved for paper authors to work with workshop attendees to strengthen, expand, or revise their ideas. The updated papers will be presented in the afternoon with discussions to inspire new line of research and development.  

## Workshop themes:
The workshop is dedicated to studying AI-based solutions to multimodal HRI, and to feeding AI with socially acceptable, trustworthy and effective multimodal HRI data.   It is aimed at participants with diverse backgrounds ranging from AI, robotics, interaction and speech technology, machine learning, computer vision, social psychology, and multimodal interaction. The discussions in the workshop will be organised around specific themes, based on the participants' submissions. We seek contributions on (but not limited to) the following topics:
 
* Methods and architectures (e.g., learning in HRI, interactive machine learning, cognitive architectures for HRI, autonomous systems)
* Rich communication capabilities (e.g., multimodal interaction, nonverbal communication, social signals, challenges for machine learning, availability of suitable data).
* Interactive social robots (e.g., spoken dialogues for HRI, natural language processing for HRI, mutual adaptation, machine ethics, human-machine trust)
* Complexity of reasoning (e.g., planning for interaction, explainable AI, knowledge representation, transfer learning: new tasks, new robots, new users).
* Social and ethical implications of AI (e.g., biased AI systems, workforce replacement, ethics of creating AI) 

## ----------------------------------------------------
## Tentative schedule (might be subject to adjustments)
## coming up soon
## ----------------------------------------------------
(Papers will also be made available shortly)
Saturday, July 14:
08:45-09:00 Welcome
09:00-10:00 Invited speaker: Elisabeth Andre - Socially sensitive technologies
10:00-10:30 Coffee break
10:30-11:20 Paper presentations (10min each) and discussion session: Socially sensitive technologies:
	* Nick Campbell: Using Multimodal Information to Support Spoken Dialogue Interaction between Humans and Robots without Intrusive 	   	Language processing
	* Vladislav Maraev, Chiara Mazzocconi, Christine Howes and Jonathan Ginzburg: Integrating laughter into spoken dialogue systems: 		preliminary analysis and suggested programme
11:20-11:30 Short break
11:30-12:30 Paper presentations (10min each) and discussion session: Cognition: Mindreading and reasoning
	* Koki Ijuin, Shohei Fujio, Albara Khalifa, Tsuneo Kato and Seiichi Yamamoto: Comparison on Effect of Eye Gaze Activities 			between Human-human and Human-robot Conversations in Second-Language
	* Hung-Hsuan Huang, Seiya Kimura, Kazuhiro Kuwabara and Toyoaki Nishida: Proposal of a Multimodal Framework for Generating 			Robot’s Spontaneous Attention Directions and Nods in Group Discussion
	* Momina Rizwan, Volkan Patoglu and Esra Erdem: Human-Robot Collaborative Assembly Planning using Hybrid Conditional Planning
12:20-13:30 Lunch
13:30-14:30 Invited speaker: Matthias Scheutz -  "Is that what you want?" Architectural Challenges of Engaging in Multi-Modal Natural 			Language Interactions with Humans
14:30-15:30 Paper presentations (10min each) and discussion session: Interaction frameworks
	* Sam Thellman and Tom Ziemke: Studying the Craft of Folk Psychology in HRI
	* Elin Anna Topp and Jacek Malec: A Knowledge Based Approach to User Support for Robot Programming
	* Mark Philipsen, Matthias Rehm and Thomas Moeslund: Industrial Human-Robot Collaboration
15:30-16:00 Coffee break
16:00-17:00 Paper presentations (10min each) and discussion session: Data and AI technologies for HRI
	* Gerard Bailly and Frédéric Elisei: Demonstrating and learning multimodal socio-communicative behaviors for HRI
	* Adrian Simon Bauer, Peter Birkenkampf, Alin Albu-Schäffer and Daniel Leidner: Bridging the Gap Between Supervised Autonomy and 		Teleoperation
	* Neziha Akalin, Andrey Kiselev, Annica Kristoffersson and Amy Loutfi: Enhancing Social Human-Robot Interaction with Deep 			Reinforcement Learning
Sunday, July 15:
09:00-10:00 Invited speaker: Amit Kumar Pandey - Socially intelligent robots and societal applications
10:00-10:30 Coffee break
10:30-12:30 Paper presentations (10min each) and discussion session: Robots and dialogue modelling
	* Kristiina Jokinen: AI-based Dialogue Modelling for Social Robots
	* Katsuyoshi Yamagami, Hirokazu Kiyomaru and Sadao Kurohashi: Knowledge-based Dialog Approach for Exploring User's Intention
	* Ioannis Papaioannou, Christian Dondrup and Oliver Lemon: Human-Robot Interaction Requires More Than Slot Filling - Multi-			Threaded Dialogue for Collaborative Tasks and Social Conversation
12:30- ? Wrap-up, closing remarks, lunch, and an optional continued discussion / workshop

## Submissions:
The workshop is closed for submissions.
<!-- The workshop accepted submissions (2-4 pages) of two forms: position papers that will form the basis of the themed sessions and discussions, and extended abstracts that will form the basis of the poster session.
Position papers should offer a statement or illustration of how the authors' work connects, contrasts, or integrates aspects of AI and Multimodal HRI. Authors are also encouraged to speak more broadly about the role that their research can play in bringing together the individual contributions from the AI, Multimodal signal processing, and HRI communities into a cohesive view of AI-MHRI.  
Accepted position papers will be posted on the workshop website before the conference, and then on ISCA/ACM archive. The authors are encouraged to update these papers both during the workshop (in the writing sessions on Day 2) and after the workshop as possible submissions to a publication in a suitable journal.
	Extended abstracts for the poster session can feature theoretical, empirical, or technical contributions. Each accepted poster contributor will introduce their take-home message in a 1-minute lightning presentation just before the poster session. 
	All submissions should observe the above page limits and follow IJCAI formatting requirements, except that submissions should contain author names (reviewing will not be double-blind).
	Submission site is closed for new submissions.-->
<!--- will be accepted through Easychair at [https://easychair.org/conferences/?conf=aimhri2018](https://easychair.org/conferences/?conf=aimhri2018). -->

## Final Submissions:
Should be available for preparation of attendance shortly.
<!-- Will be accepted through Easychair at [https://easychair.org/conferences/?conf=aimhri2018](https://easychair.org/conferences/?conf=aimhri2018). -->

## Important dates:
* **May 14:** Paper submission deadline (extended!)
* **May 28:** Author notification (planned)
* **June 29:** Publication of camera ready material (tentative)
* **July 14/15:** The AI-MHRI workshop

## -----------------
## Registration information:
To register to the workshop, please use the general registration forms for FAIM workshops, accessible for instance through the registration forms for IJCAI/ECAI at [https://www.ijcai-18.org/register/](https://www.ijcai-18.org/register/). The workshop has the id-number W27.
## -----------------

## Venue and general information
The workshop (with id W27) will take place at the AAMAS / ICMAL / IJCAI conference venue (Stockholmsmässan), presumably in room K24 on July 14 (all day) and July 15 (morning session only). Please check the conference workshop website at [https://www.ijcai-18.org/workshops/](https://www.ijcai-18.org/workshops/) for potential updates. 
For recommendations regarding accommodation in the area or in central Stockholm, please check the general information at [https://www.ijcai-18.org](https://www.ijcai-18.org).

## Organisers:
* Gérard Bailly, GIPSA-Lab, Univ. of Grenoble-Alps, France
* Laura Hiatt, NRL, Washington DC, USA
* Kristiina Jokinen, AIRC, AIST Tokyo Waterfront, Japan
* Tatsuya Kawahara, Kyoto Univ., Japan
* Roger Moore, Univ. of Sheffield, UK
* Elin A. Topp, Lund Univ., Sweden

## Program Committee:
* Gérard Bailly, Grenoble-Alps Univ., France
* Nick Campbell, Trinity College Dublin, Ireland
* Mary Ellen Foster, University of Glasgow, UK
* Anders Green, Södertorn University, Sweden
* Marc Hanheide, University of Lincoln, UK
* Laura Hiatt, NRL, Washington DC, USA
* Ayanna Howard, Georgia Tech., USA
* Hung-Hsuan Huang, Riken, Japan
* Kristiina Jokinen, AIRC, AIST Tokyo Waterfront, Japan
* Tatsuya Kawahara, Kyoto Univ., Japan
* Takanori Komatsu, Meiji Univ., Japan
* Stefan Kopp, Bielefeld University, Germany
* Yukiko Nakano, Seikei Univ., Japan
* Alessandra Sciutti, Italian Institute of Technology, Italy
* Elin Anna Topp, Lund Univ., Sweden


<!---
**A call for contributions and other details will be published here shortly.**
### Invited speakers and panelists
TBA
### Tentative dates:
**more dates will be published soon**
-->
